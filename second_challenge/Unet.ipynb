{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calde97/Deep_Learning_Challenge/blob/main/second_challenge/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZUR--WMQpuJ"
      },
      "source": [
        "# Unet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ysdFsaFLtTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb1b706-70a0-4c73-b02b-39a2926d28bd"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0OWBDCRzOlJ"
      },
      "source": [
        "## Create Dataset\n",
        "\n",
        "Remember you should move all your images under images and masks under masks.\n",
        "\n",
        "Directory structure :\n",
        "\n",
        "    - challenge2/DS/ \n",
        "                 - Images/\n",
        "                     - img1, img2, …, imgN \n",
        "                 - Masks/\n",
        "                     - img1, img2, …, imgN      \n",
        "                 - Splits\n",
        "                     - train.txt, val.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ds7XzfL0W6"
      },
      "source": [
        "%cd /content/drive/MyDrive/challenge2/DS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI_zPdSZzBwb"
      },
      "source": [
        "#The following function creates two files that contain the names of the training and validation images\n",
        "\n",
        "def write_training(images, masks, split=0.15, seed=1234, training_file_name='train.txt', validation_file_name='val.txt'):\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(images)\n",
        "  validation_split = 0.15\n",
        "  separation_index = int(split * len(images)) #Get the n-element for the splitting\n",
        "\n",
        "  #Separating the names for training and validation\n",
        "  validation_images = images[0:separation_index]\n",
        "  training_images = images[separation_index:]\n",
        "  \n",
        "  #Write the training names\n",
        "  with open('Splits/' + training_file_name, mode='w') as f:\n",
        "    for image_name in training_images:\n",
        "      image_name = image_name.split('.')[0] #Removing the .jpg postfix\n",
        "      f.write(image_name + '\\n')\n",
        "\n",
        "  #Write the validation names\n",
        "  with open('Splits/' + validation_file_name, mode='w') as f:\n",
        "    for image_name in validation_images:\n",
        "      image_name = image_name.split('.')[0] #Removing the .jpg postfix\n",
        "      f.write(image_name + '\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2HX7AgtCW1r"
      },
      "source": [
        "Take all the image and mask names in an array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Sf8Rcmz5ox"
      },
      "source": [
        "images = os.listdir('Images')\n",
        "masks = os.listdir('Masks')\n",
        "images.sort()\n",
        "masks.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTDCewWgSTXd"
      },
      "source": [
        "Creates the files under splits that contain the names of the training and validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywzh8bB23y-W"
      },
      "source": [
        "write_training(images, masks, split=0.15, seed=1234, training_file_name='train.txt', validation_file_name='val.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsMlqD4wtaLW"
      },
      "source": [
        "Create the generators\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHvVCo4yaaIz"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "cwd = os.getcwd()\n",
        "image_path = os.path.join(cwd, 'Images')\n",
        "mask_path = os.path.join(cwd, 'Masks')\n",
        "\n",
        "validation_split=0.15\n",
        "bs = 2\n",
        "img_height = 768\n",
        "img_width = 1024\n",
        "seed = 1234\n",
        "\n",
        "#Remember to delete rescale if using a different preprocess function\n",
        "train_image_data_generator = ImageDataGenerator(rescale=1/255.,\n",
        "                                                validation_split=validation_split,\n",
        "                                                width_shift_range=0.05,\n",
        "                                                height_shift_range=0.05,\n",
        "                                                rotation_range=5,\n",
        "                                                zoom_range=0.2,\n",
        "                                                horizontal_flip=True,\n",
        "                                                fill_mode='reflect')\n",
        "\n",
        "train_mask_image_data_generator = ImageDataGenerator(width_shift_range=0.05,\n",
        "                                                validation_split=validation_split,\n",
        "                                                height_shift_range=0.05,\n",
        "                                                rotation_range=5,\n",
        "                                                zoom_range=0.2,\n",
        "                                                horizontal_flip=True,\n",
        "                                                fill_mode='reflect')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsVjJV2QtjUA"
      },
      "source": [
        "Define our custom dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j73uemeaZWgt"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "class CustomDataset(tf.keras.utils.Sequence):\n",
        "\n",
        "  \"\"\"\n",
        "    CustomDataset inheriting from tf.keras.utils.Sequence.\n",
        "\n",
        "    3 main methods:\n",
        "      - __init__: save dataset params like directory, filenames..\n",
        "      - __len__: return the total number of samples in the dataset\n",
        "      - __getitem__: return a sample from the dataset\n",
        "\n",
        "    Note: \n",
        "      - the custom dataset return a single sample from the dataset. Then, we use \n",
        "        a tf.data.Dataset object to group samples into batches.\n",
        "      - in this case we have a different structure of the dataset in memory. \n",
        "        We have all the images in the same folder and the training and validation splits\n",
        "        are defined in text files.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
        "               preprocessing_function=None, out_shape=[256, 256]):\n",
        "    if which_subset == 'training':\n",
        "      subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n",
        "    elif which_subset == 'validation':\n",
        "      subset_file = os.path.join(dataset_dir, 'Splits', 'val.txt')\n",
        "    \n",
        "    with open(subset_file, 'r') as f:\n",
        "      lines = f.readlines()\n",
        "    \n",
        "    subset_filenames = []\n",
        "    for line in lines:\n",
        "      subset_filenames.append(line.strip()) \n",
        "\n",
        "    self.which_subset = which_subset\n",
        "    self.dataset_dir = dataset_dir\n",
        "    self.subset_filenames = subset_filenames\n",
        "    self.img_generator = img_generator\n",
        "    self.mask_generator = mask_generator\n",
        "    self.preprocessing_function = preprocessing_function\n",
        "    self.out_shape = out_shape\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.subset_filenames)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # Read Image\n",
        "    curr_filename = self.subset_filenames[index]\n",
        "    if (curr_filename[0] == 'R'):\n",
        "      img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.png'))\n",
        "    else:\n",
        "      img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.jpg'))\n",
        "      \n",
        "    mask = Image.open(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'))\n",
        "  \n",
        "    # Resize image and mask\n",
        "    img = img.resize(self.out_shape)\n",
        "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
        "    \n",
        "    img_arr = np.array(img)\n",
        "    mask_arr = np.array(mask)\n",
        "\n",
        "    # in this dataset 255 mask label is assigned to an additional class, which corresponds \n",
        "    # to the contours of the objects. We remove it for simplicity.\n",
        "    #mask_arr[mask_arr == 255] = 0  \n",
        "\n",
        "    ############################################################################\n",
        "    #Part added. We have to read the mask as provided by the script.\n",
        "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
        "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
        "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
        "    ############################################################################\n",
        "\n",
        "    mask_arr = np.expand_dims(new_mask_arr, -1) #Modified\n",
        "\n",
        "    if self.which_subset == 'training':\n",
        "      if self.img_generator is not None and self.mask_generator is not None:\n",
        "        # Perform data augmentation\n",
        "        # We can get a random transformation from the ImageDataGenerator using get_random_transform\n",
        "        # and we can apply it to the image using apply_transform\n",
        "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=seed)\n",
        "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=seed)\n",
        "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
        "        # ImageDataGenerator use bilinear interpolation for augmenting the images.\n",
        "        # Thus, when applied to the masks it will output 'interpolated classes', which\n",
        "        # is an unwanted behaviour. As a trick, we can transform each class mask \n",
        "        # separately and then we can cast to integer values (as in the binary segmentation notebook).\n",
        "        # Finally, we merge the augmented binary masks to obtain the final segmentation mask.\n",
        "        out_mask = np.zeros_like(mask_arr)\n",
        "        for c in np.unique(mask_arr):\n",
        "          if c > 0:\n",
        "            curr_class_arr = np.float32(mask_arr == c)\n",
        "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
        "            # from [0, 1] to {0, 1}\n",
        "            curr_class_arr = np.uint8(curr_class_arr)\n",
        "            # recover original class\n",
        "            curr_class_arr = curr_class_arr * c \n",
        "            out_mask += curr_class_arr\n",
        "    else:\n",
        "      out_mask = mask_arr\n",
        "    \n",
        "    if self.preprocessing_function is not None:\n",
        "        img_arr = self.preprocessing_function(img_arr)\n",
        "\n",
        "    return img_arr, np.float32(out_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr9XxyuQp6f1"
      },
      "source": [
        "def normalize(img):\n",
        "  return img / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOfwCJ7t8dJ"
      },
      "source": [
        "Create the train and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxHdSLJnjl8_"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
        "\n",
        "\n",
        "dataset = CustomDataset('/content/drive/MyDrive/challenge2/DS', 'training', \n",
        "                        img_generator=train_image_data_generator, mask_generator=train_mask_image_data_generator,\n",
        "                        preprocessing_function=normalize, out_shape=[img_width, img_height]) #HERE the shape is inverted => BAD thing but is was already written by the prof\n",
        "\n",
        "dataset_valid = CustomDataset('/content/drive/MyDrive/challenge2/DS', 'validation', \n",
        "                        img_generator=train_image_data_generator, mask_generator=train_mask_image_data_generator,\n",
        "                        preprocessing_function=normalize, out_shape=[img_width, img_height]) #HERE the shape is inverted => BAD thing but is was already written by the prof"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaHiWAD2kQcq"
      },
      "source": [
        "#Train dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_height, img_width, 3], [img_height, img_width, 1]))\n",
        " \n",
        "train_dataset = train_dataset.batch(bs)\n",
        " \n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "##Validation dataset\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([img_height, img_width, 3], [img_height, img_width, 1]))\n",
        " \n",
        "validation_dataset = validation_dataset.batch(bs)\n",
        " \n",
        "validation_dataset = validation_dataset.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XfiG461Wgqp"
      },
      "source": [
        "## Model architecture\n",
        "\n",
        "The architecture is a classical Unet architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhkYFEymWjRA"
      },
      "source": [
        "import tensorflow as tf\n",
        "def UNet(input_size = (896,896,3)):\n",
        "    inputs = tf.keras.layers.Input(input_size)\n",
        "    conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    conv1=tf.keras.layers.BatchNormalization()(conv1)\n",
        "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    conv2=tf.keras.layers.BatchNormalization()(conv2)\n",
        "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    conv3=tf.keras.layers.BatchNormalization()(conv3)\n",
        "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    conv4=tf.keras.layers.BatchNormalization()(conv4)\n",
        "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "    conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    conv5=tf.keras.layers.BatchNormalization()(conv5)\n",
        "    drop5 = tf.keras.layers.Dropout(0.5)(conv5)\n",
        "    up6 = tf.keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = tf.keras.layers.concatenate([conv4,up6], axis = 3)\n",
        "    conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    conv6=  tf.keras.layers.BatchNormalization()(conv6)\n",
        "    up7 = tf.keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = tf.keras.layers.concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    conv7=tf.keras.layers.BatchNormalization()(conv7)\n",
        "    up8 = tf.keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = tf.keras.layers.concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    conv8=tf.keras.layers.BatchNormalization()(conv8)\n",
        "    up9 = tf.keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = tf.keras.layers.concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 =tf.keras.layers.Conv2D(3, 1, activation = 'softmax')(conv9)\n",
        "    model = tf.keras.models.Model(inputs = inputs, outputs = conv10)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVflgArwWmkH"
      },
      "source": [
        "model = UNet(input_size=(768, 1024, 3))\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvx6Hse-TfN9"
      },
      "source": [
        "## Model compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHxdoqUmTfN9"
      },
      "source": [
        "def meanIoU(y_true, y_pred):\n",
        "    # get predicted class from softmax\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
        "\n",
        "    per_class_iou = []\n",
        "\n",
        "    for i in range(1,3): # exclude the background class 0\n",
        "      # Get prediction and target related to only a single class (i)\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
        "    \n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "      per_class_iou.append(iou)\n",
        "\n",
        "    return tf.reduce_mean(per_class_iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQAh7k9R28vY"
      },
      "source": [
        "def IoUCrop(y_true, y_pred):\n",
        "    # get predicted class from softmax\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
        "\n",
        "    per_class_iou = []\n",
        "\n",
        "    for i in range(1,2): # exclude the background class 0\n",
        "      # Get prediction and target related to only a single class (i)\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
        "    \n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "      per_class_iou.append(iou)\n",
        "\n",
        "    return tf.reduce_mean(per_class_iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErY_CQ9a3BgF"
      },
      "source": [
        "def IoUWeed(y_true, y_pred):\n",
        "    # get predicted class from softmax\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
        "\n",
        "    per_class_iou = []\n",
        "\n",
        "    for i in range(2,3): # exclude the background class 0\n",
        "      # Get prediction and target related to only a single class (i)\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
        "    \n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "      per_class_iou.append(iou)\n",
        "\n",
        "    return tf.reduce_mean(per_class_iou)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgoK4nArTfN9"
      },
      "source": [
        "metrics = ['accuracy', meanIoU, IoUCrop, IoUWeed]\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
        "# learning rate\n",
        "lr = 1e-4\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7Jwh6FMTfN9"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/challenge2/DS/experiment_results_unet --port 6005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ewjcWGTfN9"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "exps_dir = 'experiment_results_unet'\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "    \n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "# ----------------\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                   save_weights_only=True,\n",
        "                                                   save_best_only=False)  # False to save the model directly\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "# ---------------------------------\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    \n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = True\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "\n",
        "# How to visualize Tensorboard\n",
        "\n",
        "# 1. tensorboard --logdir EXPERIMENTS_DIR --port PORT     <- from terminal\n",
        "# 2. localhost:PORT   <- in your browser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVWdGKUqQhjR"
      },
      "source": [
        "## Model fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiPQJoD1rwRu"
      },
      "source": [
        "There were 2 trainings due to a colab timeout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjPX9hasl28I",
        "outputId": "58854151-2d26-468d-e3bb-5a33648d4bd8"
      },
      "source": [
        "model.fit(x=train_dataset,\n",
        "          epochs=100,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(dataset),\n",
        "          validation_data=validation_dataset,\n",
        "          validation_steps=len(dataset_valid), \n",
        "          callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "612/612 [==============================] - 1515s 2s/step - loss: 0.0972 - accuracy: 0.9619 - meanIoU: 0.5677 - val_loss: 0.2124 - val_accuracy: 0.9068 - val_meanIoU: 0.4697\n",
            "Epoch 2/100\n",
            "612/612 [==============================] - 1255s 2s/step - loss: 0.0759 - accuracy: 0.9707 - meanIoU: 0.6552 - val_loss: 0.1501 - val_accuracy: 0.9413 - val_meanIoU: 0.5067\n",
            "Epoch 3/100\n",
            "612/612 [==============================] - 1242s 2s/step - loss: 0.0664 - accuracy: 0.9746 - meanIoU: 0.6991 - val_loss: 0.1395 - val_accuracy: 0.9547 - val_meanIoU: 0.5607\n",
            "Epoch 4/100\n",
            "612/612 [==============================] - 1209s 2s/step - loss: 0.0583 - accuracy: 0.9774 - meanIoU: 0.7315 - val_loss: 0.1011 - val_accuracy: 0.9643 - val_meanIoU: 0.6027\n",
            "Epoch 5/100\n",
            "612/612 [==============================] - 1245s 2s/step - loss: 0.0526 - accuracy: 0.9793 - meanIoU: 0.7538 - val_loss: 0.0961 - val_accuracy: 0.9663 - val_meanIoU: 0.5998\n",
            "Epoch 6/100\n",
            "612/612 [==============================] - 1236s 2s/step - loss: 0.0475 - accuracy: 0.9809 - meanIoU: 0.7747 - val_loss: 0.0933 - val_accuracy: 0.9682 - val_meanIoU: 0.6054\n",
            "Epoch 7/100\n",
            "129/612 [=====>........................] - ETA: 15:03 - loss: 0.0463 - accuracy: 0.9814 - meanIoU: 0.7899"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "lo58MaXhlvm9",
        "outputId": "55cdbe18-8029-4a67-c2f5-ffc991c04260"
      },
      "source": [
        "model.fit(x=train_dataset,\n",
        "          epochs=100,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(dataset) / bs,\n",
        "          validation_data=validation_dataset,\n",
        "          validation_steps=len(dataset_valid) / bs, \n",
        "          callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "612/612 [==============================] - 1915s 3s/step - loss: 0.0456 - accuracy: 0.9816 - meanIoU: 0.7820 - val_loss: 0.1080 - val_accuracy: 0.9654 - val_meanIoU: 0.6424\n",
            "Epoch 2/100\n",
            "612/612 [==============================] - 1205s 2s/step - loss: 0.0419 - accuracy: 0.9828 - meanIoU: 0.7964 - val_loss: 0.0933 - val_accuracy: 0.9699 - val_meanIoU: 0.6741\n",
            "Epoch 3/100\n",
            "612/612 [==============================] - 1185s 2s/step - loss: 0.0394 - accuracy: 0.9837 - meanIoU: 0.8064 - val_loss: 0.0912 - val_accuracy: 0.9710 - val_meanIoU: 0.6659\n",
            "Epoch 4/100\n",
            "612/612 [==============================] - 1209s 2s/step - loss: 0.0362 - accuracy: 0.9848 - meanIoU: 0.8186 - val_loss: 0.0946 - val_accuracy: 0.9709 - val_meanIoU: 0.6483\n",
            "Epoch 5/100\n",
            "612/612 [==============================] - 1239s 2s/step - loss: 0.0370 - accuracy: 0.9846 - meanIoU: 0.8157 - val_loss: 0.0996 - val_accuracy: 0.9679 - val_meanIoU: 0.6402\n",
            "Epoch 6/100\n",
            " 65/612 [==>...........................] - ETA: 16:34 - loss: 0.0331 - accuracy: 0.9861 - meanIoU: 0.8384"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-08a610a08613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNvlHrEI5GZF"
      },
      "source": [
        "## Compute predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H157eZTa5nj6"
      },
      "source": [
        "Creating all the test generators for computing the predictions. \n",
        "The target size should be the one used during the model training for better performances.\n",
        "All the paths correspond to the paths in which all the images are saved"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbKQUfmH5loM",
        "outputId": "eff88927-e764-4f47-813e-dc63ea6f31d0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "seed = 1234\n",
        "h = 768\n",
        "w = 1024\n",
        "\n",
        "test_image_data_generator = ImageDataGenerator(rescale=1/255.)\n",
        "test = test_image_data_generator.flow_from_directory('/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Bipbip/Haricot' #path to test images\n",
        "                                                     ,classes=None, batch_size=1,\n",
        "                                                     shuffle=False,\n",
        "                                                     target_size=(h,w),\n",
        "                                                     interpolation='bilinear',\n",
        "                                                     seed=seed)\n",
        "\n",
        "test1 = test_image_data_generator.flow_from_directory('/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Bipbip/Mais',                                    \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(h,w),\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      seed=seed)\n",
        "test2 = test_image_data_generator.flow_from_directory(\n",
        "                                                      '/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Pead/Haricot' ,                                   \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      target_size=(h,w),\n",
        "                                                      seed=seed)\n",
        "test3 = test_image_data_generator.flow_from_directory(\n",
        "                                                      '/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Pead/Mais'     ,                               \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(h,w),\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      seed=seed)\n",
        "test4 = test_image_data_generator.flow_from_directory(\n",
        "                                                      '/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Roseau/Haricot' ,                                   \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(h,w),\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      seed=seed)\n",
        "test5 = test_image_data_generator.flow_from_directory(\n",
        "                                                      '/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Roseau/Mais'  ,                                  \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(h,w),\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      seed=seed)\n",
        "test6 = test_image_data_generator.flow_from_directory(\n",
        "                                                      '/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Weedelec/Haricot',                                    \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      target_size=(h,w),\n",
        "                                                      seed=seed)\n",
        "test7 = test_image_data_generator.flow_from_directory(\n",
        "                                                      '/content/drive/MyDrive/challenge2/Development_Dataset/Test_Dev/Weedelec/Mais',                                    \n",
        "                                                      classes=None, batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(h,w),\n",
        "                                                      interpolation='bilinear',\n",
        "                                                      seed=seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n",
            "Found 15 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKkXD5gX-QV2"
      },
      "source": [
        "\n",
        "#Take list of test generators and returns their names \n",
        "def names_from_test_generator(generator:list):\n",
        "  list_result = []\n",
        "  for gen in generator:\n",
        "    result = []\n",
        "    for elem in gen.filenames:\n",
        "      result.append(elem.split('/')[1].split('.')[0])\n",
        "    list_result.append(result)\n",
        "  return list_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhGpo7c5Btl6"
      },
      "source": [
        "#Take the list of test generator and return the predictions\n",
        "#We could do the upsampling after the model.predict\n",
        "def predictions_from_generator(generator:list, model):\n",
        "  list_result = []\n",
        "  for gen in generator:\n",
        "    result = []\n",
        "    predictions = model.predict(gen, batch_size=1)\n",
        "    for i in range(predictions.shape[0]):\n",
        "      result.append(predictions[i])\n",
        "    list_result.append(result)\n",
        "  return list_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg62tmZI40YL"
      },
      "source": [
        "Create list of test-generator. Get the names and the respective predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejMrQuzjCs0m"
      },
      "source": [
        "test_list = [test, test1, test2, test3, test4, test5, test6, test7] #All the test generators of the different classes\n",
        "names = names_from_test_generator(test_list) #Get names of the images\n",
        "predictions = predictions_from_generator(test_list, model) #Assuming model is your trained model. Get prediction of the images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K39u_X6mRzyf"
      },
      "source": [
        "The encode function was provided by the starting kit of the challenge. We adapted it for our custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky0H6iQADfK1"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - foreground, 0 - background\n",
        "    Returns run length as string formatted\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "#Function to create the json file \n",
        "#The cv2 function inverts height with width :(\n",
        "def submit(names:list, predictions:list):\n",
        "\n",
        "    submission_dict = {}\n",
        "    for img_name, mask_arr in zip(names[0], predictions[0]):\n",
        "\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(2048, 1536), interpolation=cv2.INTER_NEAREST) #The cv2 function inverts height with width :(\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Bipbip'\n",
        "      submission_dict[img_name]['crop'] = 'Haricot'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "    \n",
        "    for img_name, mask_arr in zip(names[1], predictions[1]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(2048, 1536), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Bipbip'\n",
        "      submission_dict[img_name]['crop'] = 'Mais'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "    for img_name, mask_arr in zip(names[2], predictions[2]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(3280, 2464), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Pead'\n",
        "      submission_dict[img_name]['crop'] = 'Haricot'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "    for img_name, mask_arr in zip(names[3], predictions[3]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(3280, 2464), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Pead'\n",
        "      submission_dict[img_name]['crop'] = 'Mais'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "    for img_name, mask_arr in zip(names[4], predictions[4]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(1227, 819), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Roseau'\n",
        "      submission_dict[img_name]['crop'] = 'Haricot'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "    for img_name, mask_arr in zip(names[5], predictions[5]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(1227, 819), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Roseau'\n",
        "      submission_dict[img_name]['crop'] = 'Mais'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "    for img_name, mask_arr in zip(names[6], predictions[6]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(5184, 3456), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Weedelec'\n",
        "      submission_dict[img_name]['crop'] = 'Haricot'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "\n",
        "    for img_name, mask_arr in zip(names[7], predictions[7]):\n",
        "      f = tf.argmax(mask_arr, -1)\n",
        "      mask_arr = np.array(f)\n",
        "      mask_arr = cv2.resize(mask_arr, dsize=(5184, 3456), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = mask_arr.shape\n",
        "      submission_dict[img_name]['team'] = 'Weedelec'\n",
        "      submission_dict[img_name]['crop'] = 'Mais'\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # RLE encoding\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode(mask_arr == 1)\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode(mask_arr == 2)\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "    \n",
        "    with open('submission.json', 'w') as f:\n",
        "        json.dump(submission_dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQcJ92i0DL-j"
      },
      "source": [
        "submit(names, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}